{% from 'macros.jinja' import node_llm_config_to_dspy_lm %}

import dspy
import os
from typing import Dict, Any, List, Optional, Union, cast
from langwatch_nlp.studio.dspy.llm_node import LLMNode

{% set class_name = component.name or "AnonymousSignature" %}
{% set field_type_to_dspy_type = {
    "image": "dspy.Image",
    "str": "str",
    "int": "int",
    "float": "float",
    "bool": "bool",
    "list_str": "list[str]"
} %}

{% set prompting_technique_map = {
    "ChainOfThought": "dspy.ChainOfThought",
} %}

class {{ class_name }}Signature(dspy.Signature):
    {% if parameters.get('instructions', '') %}
    """{{ parameters.get('instructions', '') }}"""

    {% endif %}
    {% for input_field in component.inputs or [] %}
    {{ input_field.identifier }}: {{ field_type_to_dspy_type[input_field.type.value] }} = dspy.InputField()
    {% endfor %}
    {% for output_field in component.outputs or [] %}
    {{ output_field.identifier }}: {{ field_type_to_dspy_type[output_field.type.value] }} = dspy.OutputField()
    {% endfor %}
    {% if not component.inputs and not component.outputs %}
    pass
    {% endif %}


class {{ class_name }}(LLMNode):
    def __init__(self):
        {% set ns = namespace(decorator_node=None) %}
        {% if prompting_technique %}
        {# Apply prompting technique decorator #}
        {% for node in workflow.nodes %}
            {% if node.id == prompting_technique.ref %}
                {% set ns.decorator_node = node %}
            {% endif %}
        {% endfor %}
        {% if ns.decorator_node %}
        predict = {{ prompting_technique_map[ns.decorator_node.data.cls] }}({{ class_name }}Signature)
        {% else %}
        {# Decorator node {{ prompting_technique.ref }} not found #}
        predict = dspy.Predict({{ class_name }}Signature)
        {% endif %}
        {% else %}
        {# Standard prediction #}
        predict = dspy.Predict({{ class_name }}Signature)
        {% endif %}

        {# Configure LLM #}
        {% if llm_config %}
        lm = {{ node_llm_config_to_dspy_lm(llm_config) }}
        {% else %}
        {{ raise("LLM is required for " ~ component.name) }}
        {% endif %}

        {# Process demonstrations if available #}
        {% if demonstrations %}
        demos = {{ demonstrations.__repr__() }}
        {% endif %}

        super().__init__(
            node_id="{{ node_id }}",
            name="{{ class_name }}",
            predict=predict,
            lm=lm,
            {% if demonstrations %}
            demos=demos
            {% endif %}
        )
